This is a toy C++ compiler for learning and experimentation purposes. It is not for production use.

The ideal goals of this compiler are:
    - Conforming to C++20 as a baseline: https://timsong-cpp.github.io/cppwp/n4861
    - Support for some proposed features as desired. Possibly a straightforward implementation path.
    - Unless necessary, performance is not a primary goal.
    - Testbed for ideas.
    - Test whether parser combinators can match up to RD for C++.
    - x86_64 and/or x86 target, or LLVM if I feel like it, or maybe just a parser.

The beginning process consisted of reading through part of the standard in order and maintaining various kinds of notes:
    -documentation for implementation-defined behaviour
    -documentation for unsupported constructs marked as conditionally-supported
    -general points of interest while reading (typically something that I might not remember, paraphrased)
    -individual small-scope tasks that must be completed
    -a list of explicit callouts as undefined behaviour
    -choices made when the standard is vague or flexible, or when I'm not sure I understand it

In addition, I started looking at how Clang works internally and testing various examples on Clang+GCC+MSVC to see how they all handle certain cases. The following are things that I thought about and decided while doing so:

Start simple and limit things to ASCII (UTF-8 later). It's more fun getting other stuff up and working while still being conforming here.

Location tracking is not trivial. It needs to ignore line splices, which prevents splicing from being completely handled before preprocessing. However, line splicing needs to still happen very generally throughout lexing.

Furthermore, #line needs to be able to change the location for diagnostics and retrieval. #line also allows its line and file information to be from expanded macros, so this updating needs to happen in tandem with preprocessing and can't be pulled out earlier.

Not only that, but locations can no longer be trusted as a means to access the original source file. The location associated with a token or AST node might not be unique, and it might not even be in the original file. When reporting diagnostics, the location needs to be checked before retrieving the original text.

At this point, I don't see the need to keep the real location around, only the fudged one.

Alongside this, I had some thoughts about preprocessing in general. Given that it can inject C++ tokens, it feels cleanest to have a separate PP. The output of the PP consists of a stream of C++ tokens, each with fudged locations and their origin (source, macro). For the sake of tooling and diagnostics, it can also output a list of macro definitions as well as expansions. Each token can refer to the expansion that produced it, which can refer to the expansion that produced that one, and so on.

With this in mind, there's one lexer to lex all tokens for both the PP and C++. The PP consumes the token sequence and produces a new sequence without the macro definitions and with final locations and replaced expansions while building the other returned information. Headers can be preprocessed in the same way.

General process at this point:
1. Source gets lexed into a stream of pptokens and whitespace tokens (line splices are handled). The original lexeme and its location can be obtained for each token.
2. Post-lexing occurs to remove whitespace and comments (but keep newlines).
3. General PP stuff happens. The most important output is a stream of C++ tokens converted from PP tokens. These have potentially more than one location because of macro expansion injecting tokens because of some original tokens.
4. Post-PP occurs to concatenate adjacent string literals.
5. Parsing produces a basic AST without name resolution.
6. It gets messy here. Name resolution, type checking, bunch of stuff that might be better doing while parsing like Clang does. Getting some form of basic AST is a good start.

The tasks at this point started taking on more of a feature-oriented approach, as well as attaching specific compiler phases. By structuring the tasks in terms of features, the compiler can support one new feature at a time. It also gives some room to play with name resolution etc. without a giant AST and experiment. This structure means future tasks can land in an existing category instead of always being lexical order in the standard.

The feature-oriented approach really encouraged me to think of how to have a minimal, but useful foundation up for getting started. For example, it helps to have a bunch of tokens represented right away because they're reused for more than one purpose ([] for arrays, operator overloading, and lambdas), but many tokens can be saved for later. This gives reasonable flexibility in tackling features in any order and examining the scalability of the design before having many features.

Regarding C++ token representation, it's convenient for parsing to have the token kind include one per keyword. However, C++ sometimes makes it convenient to aggregate these (notably, attributes treat keywords as identifiers). It should work to add one token kind per keyword, but also include a flag in the token type to indicate whether the token is an identifier with special meaning (keyword, soft keyword, alternative token). Compared to creating a parser that creates a disjunction over all of these, this avoids backtracking a million times per identifier in attributes. On the topic of alternative tokens, once preprocessing is done, those are equivalent to their corresponding token... except for attributes, but digraphs are still 100% equivalent. There are far fewer of these, meaning backtracking could be a little more bearable, though not ideal. Having one flag per alternative token seems a bit wasteful as well. Both of these might be doable if the compiler keeps track of when identifiers appear in an attribute since consecutive [ is guaranteed to start an attribute. Tokens can keep a flag for whether they're in an attribute and the conversion from pptoken to C++ token can use that. The catch is that macros can affect the [[ start via `[ LBRACKET` or similar. Therefore, this detection must be done after macro expansion, but before (or during) conversion to C++ tokens in order to let the parser deal in `&&` tokens for normal parsing and identifier tokens for attributes. There's room to do this attribute detection while converting.

For whitespace, there are two things of note. First, since whitespace can be condensed (and is in stringization), it's feasible to have each token indicate whether it has leading or trailing whitespace. Leading is preferable because it means remembering already-lexed whitespace instead of peeking ahead. The other option is discarding whitespace completely and recovering that information from the source file text. The token can be looked up and then the characters before it examined, taking care to skip line splices and add whitespace for comments like a/**/b (arbitrary lookbehind, yuck). Neither option is particularly appealing, but the token flag seems cleaner.

Second, the # in preprocessing directives must be the first non-whitespace character of the line. Two approaches for this come to mind: A flag in the token for the token starting a line or having pseudotokens for the start of a line. The pseudotoken approach looks appealing because it enables parsing based on the token kinds instead of attributes. The one extra rule would be to discard these tokens at any point in the parse other than before a #. The flag-based approach also needs to ignore block comments before the directive in order to set the flag properly. In the pseudotoken approach, comments are already gone right after lexing (you can't use concatenation to create a comment after that, thank god).

Next up is literals. The question is whether to represent different bases as different AST nodes. I believe the answer (at least currently) should be no. It means more nodes to handle in AST operations for things that are essentially the same and I don't see a point of tools knowing the difference, though they could potentially derive it from the lexeme. A less drastic option is storing the base as part of the AST node, but again, I don't see a need.

With literals comes the first instance of expressions. Expressions have a type. Type analysis requires knowing what a name is (the type of `a.b` requires knowing what `a` and `b` are, the type of `a<b>::c` could be the type of `a<b> :: c` or the type of `(a < b) > ::c`). So does parsing in general (`a*b;` can be an expression or a pointer declaration). Doing name resolution can require type analysis (`decltype(anything)::a`). These two have to go hand in hand in some way.

Declarations in C++ must precede the use of a name. That does make it tempting to keep a symbol table and update it as the parser progresses. Since name resolution needs to do type analysis, that would also need to be done alongside name resolution. This makes it hard to separate the processes, but the resulting AST shouldn't need modifications. Clang decouples the AST from the parser and leaves the parser responsible for doing grammar productions and sending out callbacks. Sema acts on those to do name resolution, type checking, and build an AST.

What I'm thinking is that the base parser can be responsible for a basic AST with no type information or name resolution, but also containing multiple subtrees in areas where parses are ambiguous (like a GLR parser). After this is constructed, grammar productions take a back seat and name resolution and typing come into play to create a final AST with no ambiguities. I'll need to carefully construct a list of all ambiguous parsing that can create different node types (e.g., `a*b`). In these cases, the tree can hold both nodes. Off the top of my head, that includes the `*` declaration/expression, `a(b)` declaration/expression, `(a)+b` and `(a)(b)` expressions, MVP (always declaration) because name information isn't available, and template angle bracket shenanigans (type/template/expression). Templates have the same problems, but they don't add more because dependent names come with `typename` and `template`. Templates can have their basic AST stored and then updated at the same time as the rest of the program. Instantiations come later.

Compilers get to choose things like the size of types. This should really depend on the platform, but I think it's fair to start out hardcoding to x86_64 and changing it later if I ever want to add more targets. This means less fiddling with boilerplate like compiler flags and more focus on the compiler itself.

Speaking of types, that's another fun topic. Since C++ places so much emphasis on complete vs. incomplete types and infinite recursion is generally avoided by not doing actions that require complete types on incomplete types (e.g., `class C : C {};`), I feel it will be worth working that distinction into my APIs. Completeness is also a property of location in the source file, so the same type name could be represented by two different type entries.

Apart from inline member function bodies, which can be delayed, name resolution can, and probably should, happen as the symbol table is being built rather than relying on location information later. However, these are different operations, so finding a way to separate them out while still running them in tandem would be nice. I believe name resolution could be a coroutine to accomplish this. The tricky part is proper interleaving. For example, `void* y = x, *x = &x;` is perfectly legal. y refers to an earlier x, while x stores its own address. To accomplish this, the symbol table generation must run up to `void* y` before name resolution does `= x`, then the symbol table generation runs to `*x` before name resolution does `&x`.

I believe this would work out if the name resolution yields each declaration and waits for the symbol table to be updated before continuing. This includes points where types change from being incomplete to being complete, such as after processing a class definition. The symbol table generation shouldn't need much in the way of context, but if it does, the context can be included. Name resolution itself would be viewed as a transformation of the basic AST into one with actual node references instead of names. Ideally, type analysis (specifically getting the type of an expression) could work with these completed nodes, but be done on demand.

There are two kinds of resolution to be done: scopes (including types) and non-scopes. This distinction is important because name resolution isn't as simple as single identifiers. Rather, there can be complex sequences such as `a::b.c`. In order to be workable, the final AST needs to remove all effort from figuring out what this is. It could be namespace::variable.instance_member, type::static_member.static_member, or other things, and invalid things aren't even listed. The AST definitely needs to differentiate between namespaces and types. Static vs. non-static might be better left as a flag. However, the name could be a function or a variable, and those need to be differentiated. Since C++ reserves :: for scope access, I think it makes sense for the basic AST to separate these into their own nodes. After that, . and -> (on pointer types) are handled more easily once the scope part is resolved to a definition. In addition, `template_name<...>` conceptually counts as a name that needs to be looked up as a specialization.

This is where the warts of name resolution need to be handled, as well as disambiguating parses. If the basic AST stores each possible parse, there should be enough information now to resolve them along the way. Most ambiguities simply require more symbol information, which exists while doing name resolution. MVP (once we're sure it exists) gets sorted out by a hardcoded rule in the standard. The real gotcha is that it's not always so simple to obtain this extra information. Template instantiations are required for something like `foo<type>::name` to figure out what kind of symbol name is. decltype(expr)::name could have *any* expr, including one that requires constant evaluation, so the compiler had better be ready to run compile-time C++ code by this point in order to get the type node for the decltype. auto exists, which means the compiler has to figure out the type from elsewhere and use that to get the node. In the case of functions returning auto, the entire function body must be checked for return statements to figure that out. These return statements could be in `if constexpr` blocks or lambdas, so the context must be considered. Function declarations can have auto that can't be resolved until the definition. These functions and variables can appear in decltype expressions.

Something else to note is that C++ sometimes allows redeclarations and redefinitions. The symbol table generation should probably handle finding errors around this and support the case of a symbol gaining a definition later. One other thing to keep in mind is that overloadable operators are names as well, including implicit casts. Potentially built-in operators too if treated as such. Implicit things are particularly problematic because they can be required to parse something else, meaning implicit conversions have to be handled that early. In order for `decltype(C{} + 5)::type foo();` to have a final AST to work with, C needs to be resolved to the class definition, + needs to be resolved, and any implicit casts need to be resolved as well. Either argument or both could be implicitly converted to their appropriate types once overload resolution happens, which requires looking up constructors and conversion operators. Destructors are also names of course.

The next problem is that C++ has some rather interesting name lookup rules. For example, in `auto C::f() -> T`, `T` includes `C` in its lookup search. Name resolution has to be flexible enough to allow for this sort of thing. This sort of definition would also need to attach itself to `C::f` and not `::f`, so generation needs to handle that as well by not assuming definitions are for the current scope. Lookup needs at least some notion of multiple scopes from which to start the search. Ideally, it also won't search common parent scopes more than once. ADL fits nicely into this category of interesting lookup rules, but it should be manageable given the other support. Two-phase lookup is even more interesting because it uses the symbol table from the point of instantiation (with adjusted scope). With the AST available, this should be doable. I'm not too familiar with some of the arcane lookup rules, so reading the standard will give me more to watch for.

I'm hoping type analysis can be done in terms of final AST nodes even though it needs to be called while creating that AST. The idea is that anything we need the type of while building it should be available. For example, `int x = foo<decltype(x)>;` can have a final AST node for x referring to the declaration (with no definition yet) to understand that x is int. By the time decltype needs to happen, a final, resolved mini-AST for the expression should already be available. The catch is that computing types can be expensive. Consider a `fib<10>::value` implemented naively. The type of that expression refers to `fib<9>::value` and `fib<8>::value`, which refer to common other types. The worst thing the compiler could do is not reuse the types it's already computed. Assuming `fib<9>::value` is fully analyzed first, by the time it hits `fib<8>::value`, it should be able to short-circuit any further analysis. The key is looking at exactly what work goes on while building the AST. `fib<10>::value` includes a basic parse of `fib<10>` and `value` as parts of a qualified name, when `fib` is a template. Name resolution finds the primary `fib` specialization and instantiates `fib<10>` to produce a new type. Doing this produces a final AST for this type, meaning substitution and then name resolution must happen for its contents. Among other things, name resolution will find `fib<9>::value` and repeat these steps to get a final AST for the new type `fib<9>`, which will also produce `fib<8>`. Back to `fib<10>`, it moves on to `fib<8>::value`, but this time the type `fib<8>` already exists and can be used with no further work. This doesn't require anything more out of the AST, just a registry of types. This is normal behaviour for C++ compilers, they retain types. Figuring out how to get rid of types without needing them again would improve memory usage without compromising speed. However, I have no ideas on that front. Perhaps with the shift to constexpr, a compiler operating on new code could get away with the naive approach of not storing the types for later. Rather than storing every instantiation permanently, it could re-instantiate the template on demand. ODR-used instantiations would appear in the binary, but could also potentially skip storing the instantiation before that. After all, it's most likely that TMP instantiations are not ODR-used.

Going back to `decltype(C{} + 5)::type foo();` for type analysis, I believe overload resolution can still work on final AST nodes here. Name resolution on this node would resolve the expression inside decltype to produce a final AST for the contents. This would trigger name resolution on each subexpression to produce nodes for the ctor call and literal. Then + is looked up to get a set of functions based on the types of the two operands. All candidates have complete AST nodes. Overload resolution happens to pick one of these nodes. During this, implicit conversions are considered, but both operands have complete AST nodes. In an evaluated context, these conversions have code associated with them. Therefore, it would be a good idea to save the effort of figuring out the casts later and adapt the given AST to include these conversions. When using declval, Clang refuses to compile the decltype part of this inside of C if C has a conversion to int, while GCC accepts it and MSVC ICEs.

Another expensive part of typing (and more) that compilers are not great at today is constexpr. Doing `foo<fib(10)>` isn't going to have types to memoize. I hear Clang got a new constexpr interpreter based on bytecode. This is an idea I was wondering about before that announcement went out, and I'm happy it seems viable. Not only does it become potentially possible to store the generated bytecode and reuse it in another compilation as long as it's up-to-date, the bytecode can be optimized using regular optimization techniques as long as UB is a hard error. This bytecode can also potentially be reused for the final binary after further optimization. The two main ways of going about doing the actual evaluation are to either create an executable and run it at compile-time to produce the result needed, which comes with caveats like losing type information and needing to retain all UB detection, or to run it in an interpreter which perhaps eases keeping track of memory allocations etc. Either way, keeping a compiled constexpr function in the interpreter and then running it in a loop is going to be faster than trying to simplify its AST with different arguments. For basic ASTs, this simplification could be done in advance and parameterized, but things like loops that run a number of times based on parameters make that much more complex.

Taking some type ideas from Clang seems sensible. Since types are long-lived, its registry of types is bare types without qualifiers. It also makes sense to start simple by storing each type and then change later. Original spelling should be preferred. For example, if a variable's type doesn't match for a function call, the variable declaration node can keep a source range for its type spelling and its name. Generalized, names in AST nodes can refer to the original source, but should probably do so through tokens because of macros. Sometimes it isn't straightforward (or possible) to keep original spelling. In cases like `auto x = "abc"s;`, it would be ideal for x to steal `operator""s`'s name reference for the return type because x doesn't have one of its own. In cases like `auto x = 5;`, the name needs to be synthesized completely. Templates potentially benefit from having both the generic name and the concrete name. Namespaces seem more like noise in most errors. Meanwhile, it's probably worth looking for type aliases of templated types if they exist (e.g., std::string is std::basic_string<char>) because it seems unlikely that such a type alias would exist if not in use, unlike non-template ones that may or may not be widely used. Diverging further from Clang, type aliases can be handled similarly, referring to the canonical type directly but having the name refer to the typedef's name. Or at least they could if reflection wouldn't distinguish type aliases. reflexpr's argument should probably be a final AST node to which it can refer. It's also invalid to refer to a type alias with a class/struct/union prefix, but that's handled before the final AST is created.

That brings up the question of how simplified the AST should be. Clang opts to keep the AST close to the original source code. Realistically, this compiler won't see too much use for toy tooling, so representing the original source isn't a huge concern. However, diagnostics still benefit from the extra information. Reflection can also evolve to require whatever original information it wants.

Coming back after a while, I'm hesitant about the GLR approach. While it sounds simple to separate things out more, maintaining a recollection of what the ambiguous AST actually represents is an extra cognitive burden and there are bound to be cases of ambiguity that are just really obscure and hard to keep in mind. From another perspective, doing name resolution and typing during parsing comes with so many advantages for simplicity. First and foremost, it matches how I think as I read and write code in order. When a name is used, it must be declared beforehand, minus a couple well-known exceptions like two-phase lookup and inline member functions. If I, as a human, have to ask my brain what each name refers to as I see them, it seems simplest for the compiler to do the same. Second, this reduces the number of names declared during most lookups. The most compelling advantage is that it resolves parsing ambiguities right then and there. For the sake of argument, a parser normally cannot parse something like `type-name identifier;` because `type-name` can be just an identifier, but actually doing these processes in tandem allows for `type-name` to be a distinct non-terminal in the parser. Furthermore, it has been my experience reading proposals that the mindset is "The compiler knows X here, so it's not a problem." Under this model, the compiler does indeed have the tools to find out, while the GLR model potentially requires a new ambiguity to be introduced and handled in separate code. At the end of the day, I want it to be straightforward to implement new things, especially those not considered from the outset. The real kicker is then trying to separate these things out again. Clang keeps the non-grammar stuff in Sema with a more general interface between.

It was at this point that I started to maintain individual design documents as a place for the most up-to-date design information, separated into logical groups such as the preprocessor. The general intent is to start simple and break things up when they get unwieldy. The log serves a purpose as a chronological view of the design's evolution. In this process, I realized a couple changes. First, alternative tokens don't need to keep track of whether they're in an attribute, they just need to become an identifier when the conversion routine knows they're in an attribute. In addition, knowing this is harder than finding the start because `]]` can appear inside an attribute, too. Therefore, the conversion needs to keep track of balancing inner tokens as well. Obviously, this belongs in a separate class used by the conversion, not in the conversion itself. It can potentially be made more general and reused for something else. Secondly, separating complete vs. incomplete types within the compiler's own types doesn't work as well as it sounds because this property is orthogonal to other properties like built-in vs. user-defined. More care needs to go into what separations to make based on usage.

(Aside: I came across a really, really bad parsing issue today: https://twitter.com/seanbax/status/1491839926639501322. In order to delay parsing member initializers, you need to know where that initializer ends (or generally, all the initializers plus the constructor body) in order to know when to start parsing the next declaration. But said fragments can contain parsing ambiguities that depend on names declared later in the class, which makes this very difficult.)